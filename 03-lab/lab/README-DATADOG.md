# Chaos Engineering Lab with Datadog

This guide explains how to run the catalog service lab with Datadog integration enabled. This will allow you to visualize the impact of chaos experiments using APM (traces), metrics, and logs.

## Prerequisites

1.  **Datadog Account:** You need a Datadog account.
2.  **Datadog Agent:** You need to have the Datadog Agent installed and running on your local machine. The Agent is responsible for collecting telemetry from the application and sending it to Datadog.
    *   **Installation Instructions:** Follow the [official Datadog instructions](https://docs.datadoghq.com/agent/supported_platforms/osx/).
    *   **Configuration:** During installation, you will need your Datadog **API Key**.
    *   **Verification:** After installation, verify that the Agent is running with the `datadog-agent status` command.

## Step 1: Install Dependencies

Navigate to the `lab` directory and install the dependencies, which now include `ddtrace`.

```bash
cd lab
pip install -r requirements.txt
```

## Step 2: Configure the Environment

For your application to communicate with the Datadog Agent, you need to export the following environment variables:

```bash
# Optional, but recommended: Datadog Agent address (default: localhost)
export DD_AGENT_HOST=localhost

# Optional, but recommended: DogStatsD port (default: 8125)
export DD_DOGSTATSD_PORT=8125

# Service name that will appear in Datadog
export DD_SERVICE="sre-lab"

# Environment (e.g., dev, staging, prod)
export DD_ENV="development"

# Your application version
export DD_VERSION="1.1.0"

# Enables log injection
export DD_LOGS_INJECTION=true
```

## Step 3: Run the Application with `ddtrace-run`

To enable automatic Datadog instrumentation (APM and Logs), you **will not** use `uvicorn` directly. Instead, you will use `ddtrace-run`, which will wrap and start `uvicorn` for you.

```bash
ddtrace-run uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

Now, your application is running and sending traces, metrics, and logs to the Datadog Agent.

## Step 4: The Hands-on Lesson in Datadog

With the application running, the lesson's focus shifts from the terminal to the Datadog platform.

### 1. Create your Observability Dashboard

Before starting the chaos, go to Datadog and create a new dashboard. Add widgets to monitor the "steady state" of your service:

*   **Requests per Second:** `trace.fastapi.request.hits`
*   **Error Rate:** `trace.fastapi.request.errors`
*   **P95 Latency (API):** `trace.fastapi.request.duration`
*   **DB Query Duration:** `catalog.db.query.duration` (Histogram)
*   **Cache Hit Rate:** `sum:catalog.cache.hit{*} / (sum:catalog.cache.hit{*} + sum:catalog.cache.miss{*})`
*   **Resilience & Saturation:**
    *   `catalog.circuit_breaker.state`: Circuit Breaker State (0=Closed, 1=Open, 0.5=Half-Open).
    *   `catalog.circuit_breaker.rejected`: Requests blocked by the Circuit Breaker.
    *   `catalog.db.pool.active`: Connections in use (Max: 5).
    *   `catalog.db.pool.exhausted`: Failures due to connection exhaustion counter.
    *   `catalog.app.memory_leak_size`: Size of the list simulating a memory leak.
*   **Chaos Configuration (Gauges):**
    *   `catalog.chaos.db_latency`, `catalog.chaos.db_failure_rate`, etc.

### 2. Run Chaos Experiments

Use the Swagger UI (`http://localhost:8000/docs`) to inject chaos.

*   **Saturation Test:** Run `curl "http://localhost:8000/products/bulk/test?requests=10"` and observe the `catalog.db.load` chart rise along with latency in Datadog.
*   **Circuit Breaker Test:** Configure `db_failure_rate: 1.0` and observe the `catalog.circuit_breaker.state` metric change to `1`.

### 3. Observe Impact in Datadog

*   **In the Dashboard:** See the charts change in real-time. Latency will rise, error rate will increase, and the DB query duration will reflect the injected latency.
*   **In APM > Traces:** Find a slow trace (duration > 3s). Click on it. You will see a "flame graph" showing exactly where the time was spent: most will be in the `asyncio.sleep` simulating the database call. **This is the visual proof of your experiment.**
*   **In Logs:** If you inject failures, you will see the error logs generated by the application, correlated with the traces that failed.

This workflow — **define, observe, experiment, analyze** — using a real observability platform is at the heart of an SRE's work.
